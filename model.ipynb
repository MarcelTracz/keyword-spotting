{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7znOPnYO0Hz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import wave\n",
    "import torch\n",
    "import hashlib\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from scipy import signal\n",
    "# from google.colab import drive\n",
    "from torchsummary import summary\n",
    "from IPython.display import Audio\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7faRfIp3_LcX"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_FREQ = 4000\n",
    "CHUNK_SIZE = 16000\n",
    "SAMPLE_RATE = 16000\n",
    "MAX_NUM_WAVS_PER_CLASS = 2**27 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "opymwIVDbLr7",
    "outputId": "fb1be4e0-8e56-41ff-d6f5-56143ffdd841"
   },
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"neehakurelli/google-speech-commands\")\n",
    "\n",
    "print(\"Path to dataset files:\", path, \"\\n\\nFiles:\\n\")\n",
    "\n",
    "# !ls /root/.cache/kagglehub/datasets/neehakurelli/google-speech-commands/versions/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-nCSh-efxul",
    "outputId": "28b5fa42-eac3-4838-d2e6-565ad2da8909"
   },
   "outputs": [],
   "source": [
    "def which_set(filename, validation_percentage, testing_percentage):\n",
    "  base_name = os.path.basename(filename)\n",
    "  hash_name = re.sub(r\"_nohash_.*$\", \"\", base_name)\n",
    "  hash_name_hashed = hashlib.sha1(hash_name.encode()).hexdigest()\n",
    "  percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                      (MAX_NUM_WAVS_PER_CLASS + 1)) *\n",
    "                      (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
    "\n",
    "  if percentage_hash < validation_percentage:\n",
    "    result = \"validation\"\n",
    "\n",
    "  elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "    result = \"testing\"\n",
    "\n",
    "  else:\n",
    "    result = \"training\"\n",
    "\n",
    "  return result\n",
    "\n",
    "\n",
    "def load_data(path, classes, validation_percentage=10, testing_percentage=10):\n",
    "  data = []\n",
    "\n",
    "  for label in os.listdir(path):\n",
    "    label_path = os.path.join(path, label)\n",
    "\n",
    "    if not label in classes or not os.path.isdir(label_path):\n",
    "      continue\n",
    "\n",
    "    for file_name in os.listdir(label_path):\n",
    "      if file_name.endswith(\".wav\"):\n",
    "        file_path = os.path.join(label_path, file_name)\n",
    "        category = which_set(file_name, validation_percentage, testing_percentage)\n",
    "\n",
    "        data.append({\n",
    "            \"File_path\": file_path,\n",
    "            \"Label\": label,\n",
    "            \"Set\": category\n",
    "        })\n",
    "\n",
    "  return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "classes = [x for x in os.listdir(path) if (x[0].islower() or x[0] == \"_\") and not \".txt\" in x]\n",
    "df = load_data(path, classes)\n",
    "print(df.head())\n",
    "\n",
    "train_data = df[df[\"Set\"] == \"training\"][[\"File_path\", \"Label\"]]\n",
    "test_data = df[df[\"Set\"] == \"testing\"][[\"File_path\", \"Label\"]]\n",
    "validation_data = df[df[\"Set\"] == \"validation\"][[\"File_path\", \"Label\"]]\n",
    "\n",
    "print(\"\\nTraining samples:\", len(train_data))\n",
    "print(\"Testing samples:\", len(test_data))\n",
    "print(\"Validation samples:\", len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YgYa2AHj9u-d",
    "outputId": "5b91dfcc-1957-4023-ea26-f9a50248c36c"
   },
   "outputs": [],
   "source": [
    "def plot_spectrogram(data):\n",
    "  fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "  ax.specgram(data, Fs=SAMPLE_RATE)\n",
    "  ax.set_title(\"Spectrogram\")\n",
    "  ax.set_xlabel(\"Time [s]\")\n",
    "  ax.set_ylabel(\"Frequency [Hz]\")\n",
    "  ax.set_ylim(0, MAX_FREQ)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_amplitude(data):\n",
    "  fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "  ax.plot(np.abs(data))\n",
    "  ax.set_title(\"Amplitude Plot\")\n",
    "  ax.set_xlabel(\"Time [s]\")\n",
    "  ax.set_ylabel(\"Amplitude\")\n",
    "  ax.grid()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "idx = 34000\n",
    "file_path = train_data.iloc[idx][\"File_path\"]\n",
    "label = train_data.iloc[idx][\"Label\"]\n",
    "audio = None\n",
    "\n",
    "with wave.open(file_path, \"r\") as wav_file:\n",
    "  audio = wav_file.readframes(CHUNK_SIZE)\n",
    "  audio = np.frombuffer(audio, dtype=np.int16)\n",
    "  audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "print(\"Label:\", label, \"\\n\\n\")\n",
    "plot_spectrogram(audio)\n",
    "print(\"\\n\")\n",
    "plot_amplitude(audio)\n",
    "print(\"\\n\")\n",
    "Audio(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L34l0oyAFcKX",
    "outputId": "b695b624-b08a-42ab-c49c-dc2d2b3ec90c"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def file_to_spectrogram(file_path, save_path):\n",
    "  with wave.open(file_path, \"rb\") as wav_file:\n",
    "    audio = wav_file.readframes(CHUNK_SIZE)\n",
    "    audio = np.frombuffer(audio, dtype=np.int16)\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(1, 1), dpi=64)\n",
    "  frequencies, times, Sxx = signal.spectrogram(audio, fs=SAMPLE_RATE)\n",
    "  Sxx = np.clip(Sxx, 1e-10, None)\n",
    "  ax.pcolormesh(times, frequencies, 10 * np.log10(Sxx, where=Sxx > 0), shading=\"auto\")\n",
    "  ax.axis(\"off\")\n",
    "\n",
    "  buf = BytesIO()\n",
    "  plt.savefig(buf, format=\"png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "  buf.seek(0)\n",
    "\n",
    "  img = Image.open(buf)\n",
    "  print(save_path)\n",
    "  img.save(save_path)\n",
    "\n",
    "  plt.close(fig)\n",
    "  buf.close()\n",
    "\n",
    "\n",
    "def save_spectrograms(data, save_dir, lbl, other=False):\n",
    "  save_path = None\n",
    "  label = None\n",
    "\n",
    "  for index, row in data.iterrows():\n",
    "    if row[\"Label\"] == lbl:\n",
    "      if other:\n",
    "        label = \"other\"\n",
    "\n",
    "      else:\n",
    "        label = row[\"Label\"]\n",
    "\n",
    "      file_path = row[\"File_path\"]\n",
    "      save_path = os.path.join(save_dir, f\"{label}_{index}.png\")\n",
    "      file_to_spectrogram(file_path, save_path)\n",
    "\n",
    "\n",
    "keywords = [\"go\", \"stop\", \"bed\"]\n",
    "\n",
    "# drive.mount(\"/content/gdrive\")\n",
    "# dir_path = \"/content/gdrive/MyDrive/EASAR/\"\n",
    "# train_path = \"/content/gdrive/MyDrive/EASAR/train_data\"\n",
    "# test_path = \"/content/gdrive/MyDrive/EASAR/test_data\"\n",
    "# validation_path = \"/content/gdrive/MyDrive/EASAR/validation_data\"\n",
    "\n",
    "# dir_path = \"\"\n",
    "train_path = \"train_data/\"\n",
    "test_path = \"test_data/\"\n",
    "validation_path = \"validation_data/\"\n",
    "\n",
    "\n",
    "# os.makedirs(dir_path, exist_ok=True)\n",
    "# os.makedirs(train_path, exist_ok=True)\n",
    "# os.makedirs(test_path, exist_ok=True)\n",
    "# os.makedirs(validation_path, exist_ok=True)\n",
    "# background_dir = \"background/\"\n",
    "# for i, file in enumerate(os.listdir(path=background_dir)):\n",
    "#   file_path = os.path.join(background_dir, file)\n",
    "#   file_to_spectrogram(file_path=file_path, save_path=os.path.join(train_path, f\"background_{i}.png\"))\n",
    "# for x in keywords:\n",
    "#   idx = classes.index(x)\n",
    "#   save_spectrograms(train_data, train_path, classes[idx])\n",
    "#   save_spectrograms(test_data, test_path, classes[idx])\n",
    "#   save_spectrograms(validation_data, validation_path, classes[idx])\n",
    "\n",
    "# for i, file in enumerate(os.listdir(\"silence_chunks/\")):\n",
    "#   save_path = os.path.join(train_path, f\"silence_{i}.png\")\n",
    "#   file_to_spectrogram(file_path=f\"silence_chunks/{file}\", save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCqwSX4OrxI4"
   },
   "outputs": [],
   "source": [
    "def sample_data(df, labels, n_samples, random_state=0):\n",
    "    grouped = df[df[\"Label\"].isin(labels)]\n",
    "    grouped_without_label = grouped.drop(columns=[\"Label\"])\n",
    "\n",
    "    sampled = grouped_without_label.groupby(grouped[\"Label\"], group_keys=False).apply(\n",
    "        lambda group: group.sample(n=min(len(group), n_samples), random_state=random_state)\n",
    "    )\n",
    "\n",
    "    sampled[\"Label\"] = grouped[\"Label\"].loc[sampled.index]\n",
    "\n",
    "    return sampled.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# n_files = lambda p: len([f for f in os.listdir(p) if os.path.isfile(os.path.join(p, f))])\n",
    "# other_classes = [cls for cls in classes if cls not in keywords]\n",
    "\n",
    "# n_keywords_train = n_files(train_path) // len(keywords)\n",
    "# n_keywords_test = n_files(test_path) // len(keywords)\n",
    "# n_keywords_validation = n_files(validation_path) // len(keywords)\n",
    "\n",
    "# n_other_train = n_keywords_train // len(other_classes)\n",
    "# n_other_test = n_keywords_test // len(other_classes)\n",
    "# n_other_validation = n_keywords_validation // len(other_classes)\n",
    "\n",
    "# samples_other_train = sample_data(df[df[\"Set\"] == \"training\"], other_classes, n_other_train)\n",
    "# samples_other_train = sample_data(df[df[\"Set\"] == \"testing\"], other_classes, n_other_test)\n",
    "# samples_other_train = sample_data(df[df[\"Set\"] == \"validation\"], other_classes, n_other_validation)\n",
    "\n",
    "# for x in other_classes:\n",
    "#   save_spectrograms(train_data, train_path, x)\n",
    "#   save_spectrograms(test_data, test_path, x)\n",
    "#   save_spectrograms(validation_data, validation_path, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQV9eXUrlUGI"
   },
   "outputs": [],
   "source": [
    "class PNGDataset(Dataset):\n",
    "  def __init__(self, root_dir, image_list=None, transform=None):\n",
    "    self.root_dir = root_dir\n",
    "    self.transform = transform\n",
    "\n",
    "    if image_list:\n",
    "      self.image_list = image_list\n",
    "\n",
    "    else:\n",
    "      self.image_list = os.listdir(self.root_dir)\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.image_list)\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img_path = os.path.join(self.root_dir, self.image_list[idx])\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    lbl = self.image_list[idx][:self.image_list[idx].find(\"_\")]\n",
    "\n",
    "    if self.transform:\n",
    "        img = self.transform(img)\n",
    "\n",
    "    return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "JOzN_K-WlkPW",
    "outputId": "5b2ae063-297f-4809-a002-0828d582d42a"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(PNGDataset(train_path, transform=transform),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(PNGDataset(test_path, transform=transform),\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True)\n",
    "\n",
    "validation_loader = DataLoader(PNGDataset(validation_path, transform=transform),\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               shuffle=True,\n",
    "                               drop_last=True)\n",
    "\n",
    "n = 4\n",
    "images, lbls = next(iter(train_loader))\n",
    "imgs = []\n",
    "image_grid = make_grid(images[:n ** 2], nrow=n, normalize=True)\n",
    "plt.imshow(image_grid.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "for i in range(n):\n",
    "  for j in range(n):\n",
    "    print(lbls[n * i + j], end=\" \")\n",
    "\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rxXnwS0JJTc"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), padding=(1, 1))\n",
    "    self.batch1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    self.act1 = nn.ReLU()\n",
    "    self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "    self.conv2 = nn.Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1))\n",
    "    self.batch2 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    self.act2 = nn.ReLU()\n",
    "    self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "    self.conv3 = nn.Conv2d(128, 256, kernel_size=(3, 3), padding=(1, 1))\n",
    "    self.batch3 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    self.act3 = nn.ReLU()\n",
    "    self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "    self.conv4 = nn.Conv2d(256, 512, kernel_size=(3, 3), padding=(1, 1))\n",
    "    self.batch4 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    self.act4 = nn.ReLU()\n",
    "    self.pool4 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "    self.flat = nn.Flatten()\n",
    "\n",
    "    self.fc5 = nn.Linear(2048, 1024)\n",
    "    self.act5 = nn.ReLU()\n",
    "\n",
    "    self.fc6 = nn.Linear(1024, 512)\n",
    "    self.act6 = nn.ReLU()\n",
    "\n",
    "    self.fc7 = nn.Linear(512, 4)\n",
    "    self.act7 = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.act1(self.conv1(x))\n",
    "    x = self.pool1(x)\n",
    "\n",
    "    x = self.act2(self.conv2(x))\n",
    "    x = self.pool2(x)\n",
    "\n",
    "    x = self.act3(self.conv3(x))\n",
    "    x = self.pool3(x)\n",
    "\n",
    "    x = self.act4(self.conv4(x))\n",
    "    x = self.pool4(x)\n",
    "\n",
    "    x = self.flat(x)\n",
    "\n",
    "    x = self.act5(self.fc5(x))\n",
    "    x = self.act6(self.fc6(x))\n",
    "    x = self.act7(self.fc7(x))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-7oRwk6CAMY"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "  classname = m.__class__.__name__\n",
    "\n",
    "  if isinstance(m, nn.Conv2d):\n",
    "    nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "  elif isinstance(m, nn.BatchNorm2d):\n",
    "    nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "    nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtlIT06zCHlv",
    "outputId": "46991d12-915d-4096-cca6-eef70b155381"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "model.apply(weights_init)\n",
    "v = (3, 32, 32)\n",
    "summary(model, input_size=v)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNA--u8PCYJ2"
   },
   "outputs": [],
   "source": [
    "lbl_map = {\"go\": 0, \"stop\": 1, \"bed\": 2, \"other\": 3}\n",
    "epochs = 50\n",
    "\n",
    "accuracy_per_epoch = []\n",
    "precision_per_epoch = []\n",
    "recall_per_epoch = []\n",
    "f1_per_epoch = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for i, (imgs, labels) in enumerate(train_loader):\n",
    "    labels = torch.tensor(([lbl_map[lbl] if lbl in keywords else lbl_map[\"other\"] for lbl in labels]))\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(imgs)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  all_labels = []\n",
    "  all_predictions = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "      labels = torch.tensor(([lbl_map[lbl] if lbl in keywords else lbl_map[\"other\"] for lbl in labels]))\n",
    "      \n",
    "      imgs, labels = imgs.to(device), labels.to(device)\n",
    "      outs = model(imgs)\n",
    "      _, predicted = torch.max(outs.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "      all_labels.extend(labels.cpu().numpy())\n",
    "      all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = precision_score(all_labels, all_predictions, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, average=\"weighted\")\n",
    "\n",
    "    accuracy_per_epoch.append(accuracy)\n",
    "    precision_per_epoch.append(precision)\n",
    "    recall_per_epoch.append(recall)\n",
    "    f1_per_epoch.append(f1)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Epoch {epoch + 1}: Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(range(1, epochs + 1), accuracy_per_epoch, label='Accuracy')\n",
    "plt.plot(range(1, epochs + 1), precision_per_epoch, label='Precision')\n",
    "plt.plot(range(1, epochs + 1), recall_per_epoch, label='Recall')\n",
    "plt.plot(range(1, epochs + 1), f1_per_epoch, label='F1 Score')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Metrics over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"Metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XLvWPvR_Cib"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model\")\n",
    "weights = torch.load(\"model\", weights_only=True)\n",
    "\n",
    "for name, param in weights.items():\n",
    "    print(name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "asar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
